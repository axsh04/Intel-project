{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc5a83b-2104-47d3-9c6c-af82ec05bbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\ai assiss\\class_env\\lib\\site-packages (from gtts) (2.32.3)\n",
      "Collecting click<8.2,>=7.1 (from gtts)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\ai assiss\\class_env\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\ai assiss\\class_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ai assiss\\class_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ai assiss\\class_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ai assiss\\class_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2025.4.26)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: click, gtts\n",
      "\n",
      "  Attempting uninstall: click\n",
      "\n",
      "    Found existing installation: click 8.2.1\n",
      "\n",
      "    Uninstalling click-8.2.1:\n",
      "\n",
      "      Successfully uninstalled click-8.2.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [click]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   -------------------- ------------------- 1/2 [gtts]\n",
      "   ---------------------------------------- 2/2 [gtts]\n",
      "\n",
      "Successfully installed click-8.1.8 gtts-2.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e68a48d0-34c7-40bd-ac6b-fd149794e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import whisper\n",
    "from gtts import gTTS\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import tempfile\n",
    "import base64\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd5246c-2b32-45b9-aede-7d8d3fb0f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper model \n",
    "whisper_model = whisper.load_model(\"base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b435a71-dc2a-42f8-acf0-6a4909cc6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load environment variables from .env\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab97710-b7c5-4710-a275-ce14a5c141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt to act like a teacher\n",
    "def initialize_messages():\n",
    "    return [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an AI teacher built for classrooms. Your job is to explain concepts clearly, \"\n",
    "            \"like a kind, knowledgeable, and engaging tutor. Use text, diagrams (describe them in words), \"\n",
    "            \"and analogies to help students understand deeply.\"\n",
    "        )\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb6376e6-4434-4007-b25f-8193d25bc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_prmt = initialize_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1efb6725-1ad5-4ba8-b1c7-6995d23906d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to audio (base64 mp3)\n",
    "def text_to_base64_audio(text):\n",
    "    tts = gTTS(text)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
    "        tts.save(temp_audio.name)\n",
    "        audio_data = open(temp_audio.name, \"rb\").read()\n",
    "    os.remove(temp_audio.name)\n",
    "    return base64.b64encode(audio_data).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29e39c8c-f7e8-47bb-ac23-fbc4d931ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def voice_teacher(audio_file):\n",
    "    global messages_prmt\n",
    "\n",
    "    # Step 1: Transcribe using Whisper\n",
    "    transcription = whisper_model.transcribe(audio_file)[\"text\"]\n",
    "    messages_prmt.append({\"role\": \"user\", \"content\": transcription})\n",
    "\n",
    "    # Step 2: Get AI reply from OpenRouter\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-r1-0528:free\",\n",
    "        \"messages\": messages_prmt\n",
    "    }\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=data)\n",
    "    result = response.json()\n",
    "\n",
    "    if \"choices\" not in result:\n",
    "        return \"<p>Sorry, something went wrong with OpenRouter!</p>\"\n",
    "\n",
    "    bot_reply = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    messages_prmt.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "\n",
    "    # Step 3: Convert bot reply to base64 mp3\n",
    "    b64_audio = text_to_base64_audio(bot_reply)\n",
    "\n",
    "    # Step 4: HTML output with auto-playing audio\n",
    "    audio_html = f\"\"\"\n",
    "    <p><b>You asked:</b> {transcription}</p>\n",
    "    <p><b>AI says:</b> {bot_reply}</p>\n",
    "    <audio autoplay controls style=\"width: 100%;\">\n",
    "        <source src=\"data:audio/mp3;base64,{b64_audio}\" type=\"audio/mp3\">\n",
    "        Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    \"\"\"\n",
    "\n",
    "    return audio_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d0e4819-4f4a-446c-b503-1ae760b494b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AI assiss\\class_env\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "# Launch Gradio app\n",
    "iface = gr.Interface(\n",
    "    fn=voice_teacher,\n",
    "    inputs=gr.Audio(type=\"filepath\", label=\"Speak your question\"),\n",
    "    outputs=gr.HTML(),\n",
    "    title=\"Voice-Enabled AI Teacher\",\n",
    "    description=\"Speak a question. It replies with voice automatically!\",\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aea2ff-62b4-4d0b-8461-c9e1625a43e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (class-env)",
   "language": "python",
   "name": "class_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
